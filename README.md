
# Inpainterz
-------------------------------
Online Demo: (colab link), Project presentation: (team ppt)


**Inpainterz**λ” 2023λ…„ μ΄μ–΄λ“λ¦Όμ¤μΏ¨3κΈ°μ—μ„ μ§„ν–‰λ κΈ°μ—…μ—°κ³„ ν”„λ΅μ νΈμ΄λ©°, ν•΄λ‹Ή κΈ°μ—…μΌλ΅ λ¶€ν„° μΈνμΈν… κΈ°μ μ— λ€ν• μ„ ν–‰μ—°κµ¬κ°λ° μ£Όμ λ¥Ό λ°›μ•„ μ§„ν–‰ν–λ‹¤.

π€ Team Members
> [κ°•λ„μ„±]() 
> [κ²½μ†ν„]() 
> [λ³€μ›…μ§„]()
> [μ†μμ§„]()
> [μ§€κ²½νΈ]()

μ£Όμ” μ•κ³ λ¦¬μ¦μΌλ΅λ” μ λ΅μƒ· λ¬λ‹ λ° λΉ„μ Όμ—μ„μ νμ΄λ°μ΄μ… λ¨λΈλ΅ μ„ λ³΄μΈ Metaμ [**SAM**(Segment Anything Models)](https://github.com/facebookresearch/segment-anything) κ³Ό ν¨μ¨μ μΈ Multi-Object Track κ·Έλ¦¬κ³  Propagationλ¥Ό μ„ν• [**DeAOT**(Decoupling features in Associating Objects with Transformers)](https://github.com/yoxu515/aot-benchmark)(NeurIPS2022)κ·Έλ¦¬κ³  [**E2FGVI** (End-to-End Framework for Flow-Guided Video Inpainting)](https://github.com/MCG-NKU/E2FGVI) μΌλ΅ μΈνμΈν…μ„ ν•λ” Workflowμ΄λ©° gradioλ΅ κµ¬ν„ν–λ‹¤.

λΉ„λ””μ¤λ¥Ό μΈνμΈν… ν•λ” κ³Όμ •μ€ λ‹¤μκ³Ό κ°™λ‹¤.

1. *λ™μμƒ λ§μ¤ν‚Ή*
   **Segmentation** & **Masking**
   λ™μμƒμ—μ„ μΈνμΈν…ν•  κ°μ²΄λ¥Ό μ„ νƒν•κ³  μ •ν™•ν•κ² νλ³„(λ¶„λ¦¬)ν•κΈ° μ„ν•΄, Segmentation κΈ°λ²•μ„ μ‚¬μ©.Β 
   ν•΄λ‹Ή λ¶€λ¶„μ΄ λ„λ½λ κ²ƒμ²λΌ λ¶„ν• λ κ°μ²΄λ¥Ό Maskingν•μ—¬, μΈνμΈν… μ•κ³ λ¦¬μ¦μ΄ μν–‰ν•  μ μκ² ν•λ‹¤.Β 
   **Tracking**, use **Long-term Memory**
   Long-term MemoryμΌλ΅ Maskingλ κ°μ²΄κ°€ νΉμ • ν”„λ μ„ λ‚΄μ—μ„ λ”°λΌ μ›€μ§μ΄λ” κ²ƒμ„ μ—°μ†μ μΌλ΅ Tracking & Maskingμ„ μν–‰ν•μ—¬ λ™μμƒ λ‚΄μ— λ¨λ“  λ§μ¤ν‚Ή μ΄λ―Έμ§€λ¥Ό μ¶”μ¶ν•λ‹¤.Β 
   
2. *λ™μμƒ μΈνμΈν…*
   **Inpainting**
   Input κ°’μΌλ΅ Maskingλ μμƒμ„ λ„£μΌλ©΄ λ³µμ›ν•΄μ•Όν•λ” λ„λ½λ μ§€μ μΌλ΅ μΈμ‹ν•λ‹¤. μ΄ κ³Όμ •μ—μ„ μ•κ³ λ¦¬μ¦μ€ μ£Όλ³€μ ν”½μ…€ μ •λ³΄λ΅ λ„λ½λ λ¶€λ¶„μ μƒ‰μƒκ³Ό ν…μ¤μ² λ“±μ„ μ¶”μ •ν•κ³  μ±„μ΄λ‹¤.Β 

3. *κ²°κ³Ό ν™•μΈ λ° μμ •*
   Inpaintingλ κ²°κ³Όλ¥Ό ν™•μΈν•κ³ , ν’μ§μ„ ν–¥μƒμ‹ν‚¤κΈ° μ„ν•΄ μ¶”κ°€μ μΈ Taskλ¥Ό μν–‰ν•λ‹¤.


**inpainterzμ νμ΄ν”„λΌμΈ**μ€ **SAM**μ΄ μƒλ΅μ΄ μ¤λΈμ νΈλ¥Ό λ™μ μΌλ΅ μλ™κ°μ§€ν•κ³  μ„Έλ¶„ν™”ν•  μ μλ„λ΅ μ§€μ›ν•λ©°, **DeAOT**λ” μ‹λ³„λ λ¨λ“  μ¤λΈμ νΈλ¥Ό μ¶”μ ν•λ” μ—­ν• μ„ λ‹΄λ‹Ήν•λ‹¤. κ²°κ³Όμ μΌλ΅ **E2FGVI**λ” μ¶”μ λμ–΄ λ§μ¤ν‚Ήλ λΉ„λ””μ¤ μμƒλ“¤μ„ μΈνμΈν…ν•λ‹¤. 

<p align="center">
<img src="assets/readme00.png" width="720">
</p>

[μμ • μ§„ν–‰μ¤‘]
## **Summary** of the algorithms used
---------
**inpainterz**μ—μ„ μ‚¬μ©ν• μ•κ³ λ¦¬μ¦μ— λ€ν• λ‚΄μ©μ„ μ”μ•½ν–λ‹¤. 
### SAM 
(Segment Anything Model) **[Paper](https://ai.meta.com/research/publications/segment-anything/)**
λ€κ·λ¨ λ°μ΄ν„°μ…‹μ΄ κµ¬μ¶•λμ§€ μ•μ•λ κΈ°μ΅΄μ Segmentation μ‘μ—…μ€ λ§¤λ² ν•™μµμ— μ†μ”λλ” μ‹κ°„κ³Ό κ·Έ λΉ„μ©μ΄ λ„λ¬΄ ν¬λ‹¤λ” λ¬Έμ κ°€ μμ—λ‹¤. LLMκ³Ό κ°™μ΄ **Zero-shot** ν•™μµ λ°©μ‹μ„ μ·¨ν•λ” λ¨λΈ, 2023λ…„ 4μ›” Metaμ—μ„ Image Segmentationκ³„μ **Foundation** λ¨λΈμ„ λ§λ“λ” κ²ƒμ„ λ©ν‘λ΅ ν”„λ΅μ νΈλ¥Ό λ°ν‘ν–λ‹¤. ??

Metaλ” λ‹¤μ μ„Έ κ°€μ§€λ¥Ό μƒλ΅­κ² μ„ λ³΄μ€λ‹¤. **Task**, **Model**, **Data**.
1. **Task** ( Promptable Segmentation Task )
	Segment Anything Taskμ ν•µμ‹¬μ€ **ν”„λ΅¬ν”„ν…μ΄ κ°€λ¥**ν•λ‹¤λ” κ²ƒμ΄λ‹¤.
	μ›ν•λ” μμ—­μ **Point**λ‚ **Box** λλ” **μμ—°μ–΄**, (+ **Mask**)λ΅ κµ¬μ„±λ ν”„λ΅¬ν”„νΈλ¥Ό μ…λ ¥ν•λ©΄, μ•„λ¬΄λ¦¬ λ¨νΈν• μ •λ³΄μΌμ§€λΌλ„ μ ν¨ν• Segmentation Maskλ¥Ό μ¶λ ¥ν•λ‹¤.
	<p align="center">
	<img src="assets/readme01.png" width="720">
	</p>
2. **Model** ( Segment Anything Model, SAM )
	μ΄λ¥Ό μ„ν• λ¨λΈμΈ SAMμ€ **λ‘ κ°μ μΈμ½”λ”**μ™€ **ν•λ‚μ λ””μ½”λ”**λ΅ κµ¬μ„±λλ‹¤.
	Image Encoderμ™€ Prompt Encoderλ΅λ¶€ν„° μ¨ μ„λ² λ”© μ •λ³΄λ¥Ό λ§¤ν•‘ν•΄ Mask Decoderκ°€ μμΈ΅λ Segmentation Maskλ¥Ό μ¶λ ¥ν•λ” κµ¬μ΅°λ‹¤. 
	
	Mask Decoderλ” Transformerμ Decoderλ¥Ό μ΅°κΈ μμ •ν• κ²ƒμΌλ΅, μ΄λ―Έμ§€ μ„λ² λ”©κ³Ό ν”„λ΅¬ν”„νΈ μ„λ² λ”©μ„ λ¨λ‘ μ—…λ°μ΄νΈ ν•κΈ° μ„ν•΄ **Self-Attention**κ³Ό **Cross-Attention**μ„ μ–‘λ°©ν–¥μΌλ΅ ν™μ©ν•λ‹¤.
	
	SAMμ Prompt Encoderμ™€ Mask Decoderλ” **κ°€λ³κ³  λΉ λ¥΄λ‹¤**.
	κ°™μ€ μ΄λ―Έμ§€ μ„λ² λ”©μ΄ μ—¬λ¬ κ°μ ν”„λ΅¬ν”„νΈμ™€ ν•¨κ» μ¬μ‚¬μ©λκΈ° λ•λ¬Έμ—, CPU ν™κ²½μ μ›Ή μƒμ—μ„ 50ms μ΄ν•μ μ†λ„λ΅ Maskλ¥Ό μμΈ΅ν•  μ μλ‹¤.
	<p align="center">	
	<img src="assets/readme02.gif" width="720">
	</p>

3. **Data** ( Segment Anythin Data Engine, SA-1B Dataset )
	Foundation λ¨λΈ κ°λ°μ— μμ–΄ κ°€μ¥ μ¤‘μ”ν• κ²ƒμ€ λ€κ·λ¨ λ°μ΄ν„°μ…‹μ΄λ‹¤.
	Segment Anythingμ€ μμ²΄μ μΈ **Data Engine**μ„ κ°λ°ν–κ³ , κ·Έ κ²°κ³Ό 10μ–µ κ°μ Maskλ¥Ό κ°€μ§„ **SA-1B** λ°μ΄ν„°μ…‹μ΄ νƒ„μƒν–λ‹¤.
	<p align="center">
	<img src="assets/readme03.png" width="720">
	</p>

### DeAOT
(Decoupling features in Associating Objects with Transformers) [**Paper**](https://arxiv.org/abs/2210.09782)

1. κΈ°μ΅΄μ AOT λ°©λ²•μ„ κ°μ„ ν•μ—¬, κ°μ²΄μ— κµ¬μ• λ°›μ§€ μ•λ” μ‹κ°μ , κ°μ²΄λ³„ νΉμ§•μ„ λ…λ¦½μ μΈ λ‘ λ¶„κΈ°μ—μ„ μ²λ¦¬, dual independent branches propagationλ¥Ό μ„ν• ν¨μ¨μ μΈ λ¨λ“μΈ Gated Propagation Module (GPM)μ„ λ„μ…ν•μ—¬ hierarchical propagationμ„ κµ¬μ„±ν•λ‹¤β€‹β€‹.

1. **VOSμ μ •μμ™€ λ°°κ²½**
	VOSλ” μ£Όμ–΄μ§„ λΉ„λ””μ¤μ—μ„ ν•λ‚ λλ” μ—¬λ¬ κ°μ²΄λ¥Ό μΈμ‹ν•κ³  λ¶„ν• ν•λ” μ¤‘μ”ν• λΉ„λ””μ¤ μ΄ν•΄ μ‘μ—…μ΄λ‹¤. μ΄ μ—°κµ¬λ” μ•κ³ λ¦¬μ¦μ΄ μ΄κΈ° ν”„λ μ„μ—μ„ μ£Όμ–΄μ§„ κ°μ²΄μ λ§μ¤ν¬λ¥Ό κΈ°λ°μΌλ΅ μ „μ²΄ λΉ„λ””μ¤ μ‹ν€€μ¤μ— κ±Έμ³ κ°μ²΄λ¥Ό μ¶”μ ν•κ³  λ¶„ν• ν•΄μ•Ό ν•λ” λ°κ°λ… VOSμ— μ¤‘μ μ„ λ‘”λ‹¤.

2. **DeAOTμ μ£Όμ” κµ¬μ„±**
	DeAOTλ” λ‘ κ°€μ§€ λ¶„κΈ°, μ¦‰ μ‹κ°μ  λ¶„κΈ°μ™€ ID λ¶„κΈ°λ΅ κµ¬μ„±λλ‹¤. μ‹κ°μ  λ¶„κΈ°λ” κ°μ²΄λ¥Ό μΌμΉμ‹ν‚¤κ³  κ³Όκ±°μ μ‹κ° μ •λ³΄λ¥Ό μμ§‘ν•λ©° κ°μ²΄ νΉμ§•μ„ μ •μ ν•λ” μ—­ν• μ„ ν•©λ‹λ‹¤. ID λ¶„κΈ°λ” μ‹κ°μ  λ¶„κΈ°μ—μ„ κ³„μ‚°λ μΌμΉ λ§µ(μ£Όμ λ§µ)μ„ μ¬μ‚¬μ©ν•μ—¬ κ³Όκ±° ν”„λ μ„μ—μ„ ν„μ¬ ν”„λ μ„μΌλ΅ ID μ„λ² λ”©μ„ μ „νν•λ‹¤.

4. **Gated Propagation Module (GPM)**: DeAOTμ—μ„λ” ν¨μ¨μ„±μ„ λ†’μ΄κΈ° μ„ν•΄ λ‹¨μΌ ν—¤λ“ μ£Όμλ¥Ό κΈ°λ°μΌλ΅ μ„¤κ³„λ GPMμ„ μ‚¬μ©ν•λ‹¤. GPMμ€ μμ²΄ μ „ν, μ¥κΈ° μ „ν, λ‹¨κΈ° μ „νμ μ„Έ κ°€μ§€ μΆ…λ¥μ κ²μ΄νΈ μ „νλ¥Ό ν¬ν•¨ν•λ‹¤.

1. **λ„¤νΈμ›ν¬ μ„Έλ¶€ μ‚¬ν•­κ³Ό νΈλ μ΄λ‹**: DeAOTλ” λ‹¤μ–‘ν• μΈμ½”λ”μ™€ λ™μΌν• FPN λ””μ½”λ”λ¥Ό μ‚¬μ©ν•λ‹¤. GPM λ¨λ“μ€ μ‹κ°μ  λ° ID μ„λ² λ”©μ μ°¨μ›μ„ μ§€μ •ν•κ³ , ν•™μµμ€ μ •μ  μ΄λ―Έμ§€ λ°μ΄ν„°μ…‹μ—μ„ μƒμ„±λ ν•©μ„± λΉ„λ””μ¤ μ‹ν€€μ¤μ™€ VOS λ²¤μΉλ§ν¬μ—μ„ μν–‰λλ‹¤.
2. **κ²°λ΅ **: DeAOTλ” κ³„μΈµμ  VOS μ „νλ¥Ό μ„ν• ν¨μ¨μ μΈ ν”„λ μ„μ›ν¬λ¥Ό μ κ³µν•λ‹¤. μ΄λ” κ³„μΈµμ  μ „νμ—μ„ μ‹κ°μ  λ° ID μ„λ² λ”©μ„ λ¶„λ¦¬ν•μ—¬ κΉμ€ μ „ν κ³„μΈµμ—μ„μ μ‹κ° μ •λ³΄ μ†μ‹¤μ„ λ°©μ§€ν•λ‹¤. 

### E2FGVI
(End-to-End Framework for Flow-Guided Video Inpainting) [**Paper**](https://arxiv.org/abs/2204.02663)

**λΉ„λ””μ¤ μΈνμΈν…**
λ¨λΈμ λ©ν‘λ” λ™μμƒ ν΄λ¦½ μ „μ²΄μ—μ„ β€μ†μƒλβ€™ μμ—­μ„ μΌκ΄€λ μ½ν…μΈ λ΅ μ±„μ°λ” κ²ƒμ΄λ‹¤. ν•μ§€λ§ λ‚¨μ€ κ³Όμ λ΅ λ³µμ΅ν• λΉ„λ””μ¤ μ‹λ‚λ¦¬μ¤μ™€ μ €ν•λ λΉ„λ””μ¤ ν”„λ μ„μ— κ΄€ν• λ¬Έμ κ°€ μλ‹¤. μ΄λ” κ³ ν’μ§ λΉ„λ””μ¤ μΈνμΈν…μ„ μ„ν•΄μ„λ” **κ³µκ°„μ  κµ¬μ΅°**μ™€ **μ‹κ°„μ  μΌκ΄€μ„±**μ„ λ¨λ‘ κ³ λ ¤ν•΄μ•Ό ν•¨μ„ μλ―Έν•λ‹¤.

**Flow-based methods** (κΈ°μ΅΄ λ°©λ²•)
- μ΄λ° μΌλ°μ μΈ νλ¦„κΈ°λ° λ°©λ²•(flow-based method)λ” μΈνμΈν…μ„ **pixel propagation** λ¬Έμ λ΅ μƒκ°ν•μ—¬ μ‹κ°„μ  μΌκ΄€μ„±μ„ μμ—°μ¤λ½κ² λ³΄μ΅΄ν•λ‹¤.
    1. flow completion(νλ¦„ μ™„μ„±) : μ†μƒλ μμ—­μ— flow field κ°€ μ—†μΌλ©΄ ν›„μμ ν”„λ΅μ„Έμ¤μ— μν–¥μ„ λ―ΈμΉλ―€λ΅ λ¨Όμ € μ¶”μ •λ optical flowκ°€ λ¨Όμ € μ™„λ£(complete) λμ–΄μ•Ό ν•λ‹¤.
    2. pixel propagation(ν”½μ…€ μ „ν) : μ•μ„ μ™„μ„±λ optical flowμ κ°€μ΄λ“(μ•λ‚΄)μ— λ”°λΌ κ°€μ‹μμ—­μ ν”½μ…€μ„ μ–‘λ°©ν–¥μΌλ΅ μ „νν•΄ μ†μƒλ λΉ„λ””μ¤μ μμ—­μ„ μ±„μ΄λ‹¤
    3. content hallucination(μ½ν…μΈ  ν™κ°) : ν”½μ…€ μ „ν ν›„, λ‚λ¨Έμ§€ λ„λ½λ μμ—­μ€ μ‚¬μ „ ν•™μµλ μ΄λ―Έμ§€ μΈνμΈν… λ„¤νΈμ›ν¬λ΅ ν™κ°μΌλ΅ μ±„μ΄λ‹¤
-  μΈνμΈν…μ λ°©λ²•μ€ μ „μ²΄ μΈνμΈν… νμ΄ν”„λΌμΈμ„ κµ¬μ„±ν•κΈ° μ„ν•΄ κ°λ³„μ μΌλ΅ μ μ©, μΈμƒμ μΈ κ²°κ³Όλ¥Ό μ–»μ„ μ μμ§€λ§, μ²μ λ‘ λ‹¨κ³„μ—μ„λ” λ§μ€ μμ‘μ—…μ΄ ν•„μ”ν•΄μ„, **κ° ν”„λ΅μ„Έμ¤λ” λ³„λ„λ΅ μν–‰**ν•΄μ•Ό ν•λ” **λ‹¨μ **μ΄ μλ‹¤.
- λ”°λΌμ„, λ‘ κ°€μ§€ μ£Όμ”ν• λ¬Έμ λ¥Ό μ•ΌκΈ°ν•λ‹¤.
    1. **μ΄μ „ λ‹¨κ³„μ—μ„ λ°μƒν• μ¤λ¥κ°€** λ„μ λμ–΄ ν›„μ†λ‹¨κ³„μ—μ„ μ¦ν­λμ–΄ **μµμΆ… μ„±λ¥μ— ν° μν–¥μ„ λ―ΈμΉ¨**
    2. **λ³µμ΅ν• μμ‘μ—… μ—°μ‚°**μ„ ν•΄μ•Όν•μ§€λ§, GPU accelerationμΌλ΅ μ²λ¦¬ν•  μ μ—†μ–΄ **λ§μ€ μ‹κ°„μ΄ μ†μ”**

	<p align="center">	
	<img src="assets/readme04.png" width="720">
	</p>

**E2FGVI** (κ°μ„ λ λ¨λΈ Fig. Ours, ) 
- λ¬Έμ μ μ„ λ³΄μ™„, μ΄μ „ λ°©λ²•κ³Ό λ‹¤λ¥΄κ² β€κ³µλ™μΌλ΅β€™(**End-to-End**) μµμ ν™” ν•  μ μμ–΄ λ³΄λ‹¤ ν¨μ¨μ μ΄κ³  ν¨κ³Όμ μΈ μΈνμΈν… ν”„λ΅μ„Έμ¤ κµ¬ν„ κ°€λ¥ν•λ‹¤.
1. Flow-Completion λ¨λ“: μ—¬λ¬ λ³µμ΅ν• λ‹¨κ³„ λ€μ‹  μ›-μ¤ν… μ™„μ„±μ„ μ„ν•΄ λ§μ¤ν‚Ή λ λΉ„λ””μ¤μ— μ§μ ‘ μ μ©ν•λ‹¤.
2. Feature Propagation λ¨λ“: pixel-level propagation κ³Όλ” λ‹¬λ¦¬, flow-guided propagation ν”„λ΅μ„Έμ¤λ” (λ³€ν•μ΄ κ°€λ¥ν• convolutionμ λ„μ›€μ„ λ°›μ•„μ„) feature space μν–‰λλ‹¤.
   β†’ ν•™μµ κ°€λ¥ν• sampling offsetκ³Ό feature-level μ—°μ‚°μ„ ν†µν•΄ **μ •ν™•ν•μ§€ μ•μ€ flowμ¶”μ •μ λ¶€λ‹΄μ„ λμ–΄μ¤**
3. Content Hallucination λ¨λ“: κ³µκ°„κ³Ό μ‹κ°„μ  μ°¨μ› λ‘ λ‹¤μ—μ„ μ¥κ±°λ¦¬ μΆ…μ†μ„±μ„ ν¨κ³Όμ μΌλ΅ λ¨λΈλ§ν•κΈ° μ„ν•΄ temporal focal transformer(μ‹κ°„μ  μ΄μ  λ³€ν™κΈ°)λ¥Ό μ μ•ν•λ‹¤.
   β†’ μ΄ λ¨λ“μ—μ„ λ΅μ»¬ λ° λΉ„λ΅μ»¬ μ‹κ°„μ  μ£Όλ³€ μ΄μ›ƒ(local and non-local temporal neighbors)μ„ λ¨λ‘ κ³ λ ¤ν•μ—¬, **λ³΄λ‹¤ μ‹κ°„μ μΌλ΅ μΌκ΄€λ μΈνμΈν… κ²°κ³Ό**λ¥Ό λ„μ¶ν•λ‹¤.
>
- 70κ°μ ν”„λ μ„ κΈ°μ¤€μΌλ΅ μ΄ ν¬κΈ°μ λΉ„λ””μ¤ ν•λ‚λ¥Ό μ™„μ„±ν•λ” λ°μ— μ•½ 4λ¶„ μ†μ”λκ³ , E2FGVIλ” ν”„λ μ„λ‹Ή 0.12μ΄λ΅ μ•½ 8.4μ΄ μ†μ”λλ‹¤.



## Inpainterz PJT Review

### κµ¬μ„±ν• Appμ ν•κ³„μ 
- λΉ λ¥΄κ² μ›€μ§μ΄λ” λ€μƒκ³Ό λ€μƒμ— κ°„μ„­μ΄ μ§€μ†μ μΌλ΅ μ΄λ£¨μ–΄μ§€λ” κ²½μ° memoryλ¥Ό λ†“μΉλ‹¤. (e.g. λ„μ¤ μμƒ)
- κ²½κ³„κ°€ λλ ·ν•μ§€ μ•μ€ κ°μ²΄(λ²½μ κ· μ—΄)λ“±μ„ inpaintingν•κ³ μ ν•λ” κ²½μ° μ λ™μ‘λμ§€ μ•λ‹¤.
  
### νκ³  λ° κ°μ„ κ°€λ¥ν• λ°©ν–¥λ“¤
- μ΄λ―Έμ§€μ μ²« λ‹¨μ— λ“±μ¥ν•λ” κ°μ²΄κ°€ μ•„λ‹ μ¤‘κ°„μ΄λ‚ λμ— μ‚½μ…λλ” κ°μ²΄λ¥Ό κΈ°μ–µν•λ” μ•κ³ λ¦¬μ¦μ΄λ‹¤.
- SOTA inpainting μ•κ³ λ¦¬μ¦μ„ μ μ©ν•μ—¬ λ” μμ—°μ¤λ¬μ΄ κ°μ²΄ μ κ±°ν•  μ μλ‹¤.




## Getting Started
-----
π® 1. Conda Default Environment
```shell
pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113
pip install mmcv-full==1.4.8 -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11/index.html
pip install gradio==3.39
pip install av
pip install gdown
```

π“‘ 2. Requirements
- The Segment-Anything repository has been cloned and renamed as sam, and the aot benchmark repository has been cloned and renamed as aot.

- Please check the dependency requirements in SAM and DeAOT and E2FGVI.

- The implementation is tested under python 3.9, as well as pytorch 1.11.0+cu113 and torchvision 0.12.0+cu113 We recommend equivalent or higher pytorch version.
  
-  Use the install.sh to install the necessary libs for **Inpainterz**
  ```
  bash script/install.sh
  ```

β­ 3. Model Preparation
- Download **SAM** model to **ckpt**, the default model is SAM-VIT-B (sam_vit_b_01ec64.pth).
  
- Download **DeAOT/AOT** model to **ckpt**, 
  the default model is R50-DeAOT-L (R50_DeAOTL_PRE_YTB_DAV.pth).

- Download **Grounding-Dino** model to **ckpt**, 
  the default model is GroundingDINO-T (groundingdino_swint_ogc).

- Download **E2fgvi** model to **ckpt**, 
  the default model is E2FGVI-CVPR22 (E2FGVI-CVPR22.pth)

- You can download the default weights using the command line as shown below.
  ```
  bash script/download_ckpt.sh
  ```


## License
---------------------
μ¤ν”μ†μ¤λ¥Ό μ§€ν–¥ν•©λ‹λ‹¤. 

SAM, DeAOTλ” μƒμ—…μ  μ΄μ©κΉμ§€ κ°€λ¥ν• μ¤ν”μ†μ¤μ…λ‹λ‹¤.

ν•μ§€λ§ E2FGVIλ” μƒμ—…μ μΌλ΅λ” μ΄μ©ν•  μ μ—†κΈ°μ— μ¶”κ°€ν™•μΈν•μ‹κΈ° λ°”λλ‹λ‹¤.



## Acknowledgement
---------
This repository is maintained byΒ **Inpainterz** [κ°•λ„μ„±]()Β andΒ [κ²½μ†ν„](), [λ³€μ›…μ§„](), [μ†μμ§„](), [μ§€κ²½νΈ]()

This code is based onΒ [SAM](),Β [DeAOT](),Β [SAMTrack](), andΒ [E2FGVI]().

Inspired by [Facebookresearch](https://github.com/facebookresearch/segment-anything), [z-x-yang](https://github.com/z-x-yang/Segment-and-Track-Anything), and [MCG-NKU](https://github.com/MCG-NKU/E2FGVI).
